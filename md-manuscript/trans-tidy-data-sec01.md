## はじめに

データ分析の80%がデータのクリーニングと準備の過程に費やされていると言われることがしばしばある (Dasu & Johnson 2003)。データの準備は、最初の段階だけにかぎられものではない。新しい問題が発生したり、新しいデータが収集されたりするたびに、分析の過程で何度も繰り返し行われる必要があるのだ。しかし、その費やされる時間の総量が膨大なものであるにもかかわらず、データをうまくクリーニングする方法についての研究は、驚くほど少ない。その難しい部分として、含まれる作業の範囲の広さがある。作業の範囲は、外れ値の確認から、日付の解析、欠損値の追究まである。本論文では、この問題に対処するために、データクリーニングにおける小さなことであるが重要な側面に着目する。データの*整然化* (tidying) と呼ぶことになるこの側面は、分析を容易にするために、データセットを構造化することを指す。

整然データの原理により、データセットの内部のデータ値を編成するための標準的手法が提供される。標準があることで、毎回何もないところから始めたり、車輪の再発明をしたりする必要がなくなるため、最初のデータクリーニングが容易になる。整然データの標準は、データに対する最初の探索と分析を容易にし、効率的に連携するデータ分析ツールの開発を簡単にするように設計されている。現行のツールは、しばしば翻訳が必要となる。別のツールに入力できるようにするには、あるツールからの出力を大規模に変更するための時間を費やす必要がある。整然データセットと整然ツールは、データ分析をより簡単にするために、協同して働く。このことにより、データに関する興味のない兵站処理でなく、興味のある領域の問題に集中することができる。

整然データの原理は、リレーショナルデータベースの原理やコッドのリレーショナル代数 (Codd 1990) の原理と密接に関連している。ただし、整然データの原理は、統計分析者が慣れた言葉で表現されている。計算機科学者も、データクリーニングの研究に大いに貢献してきた。例えば、Lakshmanan, Sadri & Subramanian (1996) は、雑然データセットを操作できるようにSQLの拡張を定義した。また、Raman and Hellerstein (2001) はデータセットをクリーニングするための枠組みを提供した。Kandel, Paepcke & Hellerstein (2011) は、データクリーニングのためのコードを自動的に生成する親しみやすいユーザーインターフェイスを備えた対話型ツールを開発している。これらのツールは有用であるが、ほとんどの統計分析者にとってなじみのない言語で書かれており、データセットをどのように構造化すべきかについて多くの助言を提供することができておらず、データ分析ツールとのつながりを欠いている。

整然データは、実世界のデータセットに取り組んだ私の経験を通じて発展してきた。編成に関する制約は、あったとしてもほんのわずかしかないため、実世界のデータセットはしばしば奇怪な方法で構築される。そのようなデータセットをデータ分析が可能になるような整ったものにすることに、私は非常に長い時間を費やしてきた。そして、データ分析が容易になるようにもしてきた。さらに、学生が自ら実世界のデータセットに対処できるように、こうしたスキルを学生に伝えることにも取り組んできた。こうした取り組みの過程で、私は `reshape` と `reshape2` (Wickham 2007) というパッケージを開発した。私は直感的にこれらのツールを使い、事例を通じて学生に教えることができたが、私の直感を明示的なものにするための枠組みはなかった。本論文はそのための枠組みを提供する。この枠組みは、包括的な「データの哲学」(philosophy of data) を提供する。これは、私のたずさわった `plyr` (Wickham 2011) と `ggplot2` (Wickham 2009) パッケージの根底にあるものである。

本論文は以下のように議論を進める。第2節では、データセットを整然たらしめる3つの特性を定義することから始める。実世界のデータセットのほとんどが整然でないことを踏まえ、第3節では、雑然データセットを整然たらしめるために必要な操作について記述し、さまざまな実例を使って技法を説明する。第4節では、整然データセットを入出力するツールである整然ツールを定義し、どのように整然データと整然ツールが協同してデータ分析を容易にするかについて議論する。これらの原理は、第5節で扱う小規模な事例研究で説明される。最後に、第6節では、この枠組みが見逃していること、および他のアプローチが議論続行に有益であるかもしれないことについて論じる。
